{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f3d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re \n",
    "\n",
    "html = requests.get(\n",
    "    \"https://www.inovacaotecnologica.com.br/noticias/noticia.php?artigo=chip-visao-neuromorfica-promete-visao-instantanea-carros-robos&id=010150250515\").content\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c28bce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seção\n",
    "secao = soup.find('div', class_='secao')\n",
    "secao = secao.get_text(strip=True) if secao else None\n",
    "\n",
    "# Título\n",
    "titulo = soup.find('h1')\n",
    "titulo = titulo.get_text(strip=True) if titulo else None\n",
    "\n",
    "# Fonte e data\n",
    "autor_data = soup.find('p', class_='suave')\n",
    "if autor_data:\n",
    "    autor_data_text = autor_data.get_text(strip=True)\n",
    "    \n",
    "    # Expressão regular para separar fonte e data com hífen colado ou com espaços\n",
    "    match = re.match(r'^(.*?)[\\s\\-–]+(\\d{2}/\\d{2}/\\d{4})$', autor_data_text)\n",
    "    if match:\n",
    "        fonte, data = match.group(1).strip(), match.group(2)\n",
    "    else:\n",
    "        fonte, data = autor_data_text, None\n",
    "else:\n",
    "    fonte, data = None, None\n",
    "\n",
    "# Legenda\n",
    "legenda_div = soup.find('div', class_='legenda')\n",
    "if legenda_div:\n",
    "    legenda_texto = legenda_div.get_text(separator=' ', strip=True)\n",
    "    legenda = legenda_texto.split('[Imagem:')[0].strip()\n",
    "else:\n",
    "    legenda = None\n",
    "\n",
    "# Exibe os resultados\n",
    "print(\"Seção:\", secao)\n",
    "print(\"Título:\", titulo)\n",
    "print(\"Fonte:\", fonte)\n",
    "print(\"Data:\", data)\n",
    "print(\"Legenda:\", legenda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14114c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paragrafos = soup.find_all('p')\n",
    "\n",
    "texto_noticia = []\n",
    "for p in paragrafos:\n",
    "    txt = p.get_text(strip=True)\n",
    "    if (\n",
    "        not txt or\n",
    "        \"redação do site inovação tecnológica\" in txt.lower() or\n",
    "        \"mais tópicos\" in txt.lower()\n",
    "    ):\n",
    "        continue\n",
    "    texto_noticia.append(txt)\n",
    "\n",
    "texto_final = '\\n\\n'.join(texto_noticia)\n",
    "print(texto_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1674b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "div_biblio = soup.find('div', class_='biblio')\n",
    "\n",
    "# Separa o texto por linhas removendo espaços extras\n",
    "linhas = [linha.strip() for linha in div_biblio.get_text(separator='\\n').split('\\n') if linha.strip()]\n",
    "\n",
    "# Inicializa variáveis\n",
    "autores = None\n",
    "revista = None\n",
    "\n",
    "# Percorre as linhas para encontrar autores e revista\n",
    "for linha in linhas:\n",
    "    if linha.startswith('Autores:'):\n",
    "        autores = linha.replace('Autores:', '').strip()\n",
    "    elif linha.startswith('Revista:'):\n",
    "        revista = linha.replace('Revista:', '').strip()\n",
    "\n",
    "print('Autores:', autores)\n",
    "print('Revista:', revista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d266a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re \n",
    "import json\n",
    "import unicodedata\n",
    "\n",
    "def normalizar_texto(texto):\n",
    "    texto = texto.lower()\n",
    "    texto = unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    texto = re.sub(r'\\s+', '-', texto)\n",
    "    texto = re.sub(r'[^\\w\\-]', '', texto)  # Remove caracteres que não são letra, número ou hífen\n",
    "    return texto\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "html = requests.get(\n",
    "    \"https://www.inovacaotecnologica.com.br/noticias/noticia.php?artigo=chip-visao-neuromorfica-promete-visao-instantanea-carros-robos&id=010150250515\").content\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Seção\n",
    "secao = soup.find('div', class_='secao')\n",
    "secao = secao.get_text(strip=True) if secao else None\n",
    "\n",
    "# Título\n",
    "titulo = soup.find('h1')\n",
    "titulo = titulo.get_text(strip=True) if titulo else None\n",
    "\n",
    "# Fonte e data\n",
    "autor_data = soup.find('p', class_='suave')\n",
    "if autor_data:\n",
    "    autor_data_text = autor_data.get_text(strip=True)\n",
    "    \n",
    "    # Expressão regular para separar fonte e data com hífen colado ou com espaços\n",
    "    match = re.match(r'^(.*?)[\\s\\-–]+(\\d{2}/\\d{2}/\\d{4})$', autor_data_text)\n",
    "    if match:\n",
    "        fonte, data = match.group(1).strip(), match.group(2)\n",
    "    else:\n",
    "        fonte, data = autor_data_text, None\n",
    "else:\n",
    "    fonte, data = None, None\n",
    "\n",
    "# Legenda\n",
    "legenda_div = soup.find('div', class_='legenda')\n",
    "if legenda_div:\n",
    "    legenda_texto = legenda_div.get_text(separator=' ', strip=True)\n",
    "    legenda = legenda_texto.split('[Imagem:')[0].strip()\n",
    "else:\n",
    "    legenda = None\n",
    "\n",
    "\n",
    "\n",
    "paragrafos = soup.find_all('p')\n",
    "\n",
    "texto_noticia = []\n",
    "for p in paragrafos:\n",
    "    txt = p.get_text(strip=True)\n",
    "    if (\n",
    "        not txt or\n",
    "        \"redação do site inovação tecnológica\" in txt.lower() or\n",
    "        \"mais tópicos\" in txt.lower()\n",
    "    ):\n",
    "        continue\n",
    "    texto_noticia.append(txt)\n",
    "\n",
    "texto_final = '\\n\\n'.join(texto_noticia)\n",
    "\n",
    "\n",
    "\n",
    "div_biblio = soup.find('div', class_='biblio')\n",
    "\n",
    "# Separa o texto por linhas removendo espaços extras\n",
    "linhas = [linha.strip() for linha in div_biblio.get_text(separator='\\n').split('\\n') if linha.strip()]\n",
    "\n",
    "# Inicializa variáveis\n",
    "autores = None\n",
    "revista = None\n",
    "\n",
    "# Percorre as linhas para encontrar autores e revista\n",
    "for linha in linhas:\n",
    "    if linha.startswith('Autores:'):\n",
    "        autores = linha.replace('Autores:', '').strip()\n",
    "    elif linha.startswith('Revista:'):\n",
    "        revista = linha.replace('Revista:', '').strip()\n",
    "\n",
    "\n",
    "arquivo = {\n",
    "        \"Origem\": \"Inovação Tecnológica\",\n",
    "        \"Seção\": secao,\n",
    "        \"Título\": titulo,\n",
    "        \"Fonte\": fonte,\n",
    "        \"Data\": data,\n",
    "        \"Legenda\": legenda,\n",
    "        \"Texto\": texto_final,\n",
    "        \"Autor\": autores,\n",
    "        \"Publicação\": revista\n",
    "    }\n",
    "\n",
    "nome_arquivo = normalizar_texto(titulo) if titulo else 'arquivo'\n",
    "\n",
    "caminho_pasta = \"'data/noticias/inovacao-tecnologica/informatica'\"\n",
    "\n",
    "    # Salva arquivo JSON\n",
    "caminho_arquivo = f\"data/noticias/inovacao-tecnologica/informatica/{nome_arquivo}.json\"\n",
    "with open(caminho_arquivo, 'w', encoding='utf-8') as f:\n",
    "    json.dump(arquivo, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12613c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def salvar_json_de_soup(soup, caminho_pasta):\n",
    "    # Função para normalizar string (remover acentos e trocar espaços por hífen)\n",
    "    def normalizar_texto(texto):\n",
    "        texto = texto.lower()\n",
    "        texto = unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('ASCII')\n",
    "        texto = re.sub(r'\\s+', '-', texto)\n",
    "        texto = re.sub(r'[^\\w\\-]', '', texto)  # Remove caracteres que não são letra, número ou hífen\n",
    "        return texto\n",
    "\n",
    "    # Seção\n",
    "    secao = soup.find('div', class_='secao')\n",
    "    secao = secao.get_text(strip=True) if secao else None\n",
    "\n",
    "    # Título\n",
    "    titulo = soup.find('h1')\n",
    "    titulo = titulo.get_text(strip=True) if titulo else None\n",
    "\n",
    "    # Fonte e data\n",
    "    autor_data = soup.find('p', class_='suave')\n",
    "    if autor_data:\n",
    "        autor_data_text = autor_data.get_text(strip=True)\n",
    "        # Expressão regular para separar fonte e data com hífen colado ou com espaços\n",
    "        match = re.match(r'^(.*?)[\\s\\-–]+(\\d{2}/\\d{2}/\\d{4})$', autor_data_text)\n",
    "        if match:\n",
    "            fonte, data = match.group(1).strip(), match.group(2)\n",
    "        else:\n",
    "            fonte, data = autor_data_text, None\n",
    "    else:\n",
    "        fonte, data = None, None\n",
    "\n",
    "    # Legenda\n",
    "    legenda_div = soup.find('div', class_='legenda')\n",
    "    if legenda_div:\n",
    "        legenda_texto = legenda_div.get_text(separator=' ', strip=True)\n",
    "        legenda = legenda_texto.split('[Imagem:')[0].strip()\n",
    "    else:\n",
    "        legenda = None\n",
    "\n",
    "    # Texto da notícia (filtrando parágrafos indesejados)\n",
    "    paragrafos = soup.find_all('p')\n",
    "    texto_noticia = []\n",
    "    for p in paragrafos:\n",
    "        txt = p.get_text(strip=True)\n",
    "        if (\n",
    "            not txt or\n",
    "            \"redação do site inovação tecnológica\" in txt.lower() or\n",
    "            \"mais tópicos\" in txt.lower()\n",
    "        ):\n",
    "            continue\n",
    "        texto_noticia.append(txt)\n",
    "    texto_final = '\\n\\n'.join(texto_noticia)\n",
    "\n",
    "    # Autores e revista na bibliografia\n",
    "    div_biblio = soup.find('div', class_='biblio')\n",
    "    autores = None\n",
    "    revista = None\n",
    "    if div_biblio:\n",
    "        linhas = [linha.strip() for linha in div_biblio.get_text(separator='\\n').split('\\n') if linha.strip()]\n",
    "        for linha in linhas:\n",
    "            if linha.startswith('Autores:'):\n",
    "                autores = linha.replace('Autores:', '').strip()\n",
    "            elif linha.startswith('Revista:'):\n",
    "                revista = linha.replace('Revista:', '').strip()\n",
    "\n",
    "    # Monta o dicionário final\n",
    "    arquivo = {\n",
    "        \"Origem\": \"Inovação Tecnológica\",\n",
    "        \"Seção\": secao,\n",
    "        \"Título\": titulo,\n",
    "        \"Fonte\": fonte,\n",
    "        \"Data\": data,\n",
    "        \"Legenda\": legenda,\n",
    "        \"Texto\": texto_final,\n",
    "        \"Autor\": autores,\n",
    "        \"Publicação\": revista\n",
    "    }\n",
    "\n",
    "    # Normaliza o título para criar o nome do arquivo\n",
    "    nome_arquivo = normalizar_texto(titulo) if titulo else 'arquivo'\n",
    "\n",
    "    # Salva arquivo JSON\n",
    "    caminho_arquivo = f\"{caminho_pasta.rstrip('/')}/{nome_arquivo}.json\"\n",
    "    with open(caminho_arquivo, 'w', encoding='utf-8') as f:\n",
    "        json.dump(arquivo, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    return arquivo, caminho_arquivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40086773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# html = requests.get(\n",
    "#     \"https://www.inovacaotecnologica.com.br/noticias/noticia.php?artigo=chip-visao-neuromorfica-promete-visao-instantanea-carros-robos&id=010150250515\").content\n",
    "\n",
    "\n",
    "# exemplo: carregue seu HTML na variável html\n",
    "soup = BeautifulSoup(\"https://www.inovacaotecnologica.com.br/noticias/noticia.php?artigo=chip-visao-neuromorfica-promete-visao-instantanea-carros-robos&id=010150250515\", 'html.parser')\n",
    "\n",
    "dados, caminho = salvar_json_de_soup(soup, 'data/noticias/inovacao-tecnologica/informatica')  # './dados' é a pasta onde salvará o arquivo\n",
    "\n",
    "print(f\"Arquivo salvo em: {caminho}\")\n",
    "print(dados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a25ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify()[:1000])  # Imprime os primeiros 1000 caracteres do HTML parseado\n",
    "https://www.inovacaotecnologica.com.br/noticias/noticia.php?artigo=chip-visao-neuromorfica-promete-visao-instantanea-carros-robos&amp;id=010150250515"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a308b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find('div', class_='secao'))\n",
    "print(soup.find('h1'))\n",
    "print(soup.find('p', class_='suave'))\n",
    "print(soup.find('div', class_='legenda'))\n",
    "print(soup.find('div', class_='biblio'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92882611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.inovacaotecnologica.com.br/noticias/noticia.php?artigo=chip-visao-neuromorfica-promete-visao-instantanea-carros-robos&id=010150250515'\n",
    "\n",
    "resp = requests.get(url)\n",
    "print(resp.status_code)  # deve ser 200\n",
    "print(resp.url)          # veja se redirecionou para outra página\n",
    "print(resp.encoding)\n",
    "\n",
    "soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "print(soup.prettify()[:1000])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
